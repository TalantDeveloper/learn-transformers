{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17273a4-e01f-44c9-a7f4-8b3bd7eb992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\develop\\learn-transformers\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331b802d-464e-4ad6-b93b-182fde38cf4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\develop\\learn-transformers\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you hoe to use this tool to remove the stain on your jeans, shirts, boots, mittens and skirts and we will introduce you to the techniques needed to do so so that you can see how to remove'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation')\n",
    "generator('In this course, we will teach you hoe to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c517fc7-c18b-44ba-98fe-82ac7d2f4a9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In this course, we will teach you how to integrate your own practice into your practice and practice.\\n\\n\\n\\nWhen we talk about your experiences using the techniques in this class, we will outline the methods using techniques in this course as they are used more often in your practice and give you some real tips of how to apply this method to the training pipeline.\\nTo summarize all the techniques you should use in this class, you should read:\\nIn this course, you will find a couple areas of problem solving used in this class.\\nThe Basics\\nEach technique will be defined by a method on how to use it. For example, let's define how to use it in a simple and familiar way in practice.\\nMethod that applies to your practice\\nTo use your technique on how to use your own practice, we'll use that method. This should be a little more specific as you will encounter multiple problems related to the learning process and how to get the information as concise as you can.\\nIn this class, you will learn how to integrate your technique into your practice. Your methods are not just useful, but will allow you to learn new methods or methods without needing to know who you are.\\nThe Basics\\nYou will learn how to add your method in this class. This is a way to introduce your method to more students. In a more general terms, you can describe your method in the following way:\\nStep 1: Insert your method in the course\\nStep 2: Insert your method in the course\\nStep 3: Make sure you have the right technique in your practice. It will be very interesting to see how this technique will get useful. If you have more time to learn, try that technique.\"},\n",
       " {'generated_text': 'In this course, we will teach you how to use your first 3-D printer in your classroom.\\n\\n\\n\\nNext step will be to read all the instruction in this course, and that course will teach you how to use your first 3-D printer in your classroom.\\nThe basic method of using your first 3-D printer is to have two sets of printer presses attached. The first set of 2 presses is a 3-D controller. As with all 3-D printers, we want to just turn them into two different shapes using a keypad.\\nFirst we are using a 3-D controller to get some 3D controllers into the printer. In this way, we want to use up the power of a single controller to get the controller to turn the controller into a 2-D controller.\\nStep 1: Making the Controller to Turn\\nUsing a 3-D controller in the classroom we want to put a 3-D controller into a set of small 3-D controller. In one of our most popular areas, we want to make the controller to turn the controller into a 2-D controller. However, the next steps will be to set the controller to turn the controller into a 3-D controller. We want our first 3-D controller to turn the controller to turn the controller to turn it into a 2-D controller. As can be seen in photos from the training course, the controller will need to be positioned as far as the center of the plane so that the 3-D printer gets on its way to any corner of the plane that will be on or off.\\n1. If the 3-D printer does not turn the 3-D printer on, then we have to place the controller in the middle of the plane as well. This way, the controller will know when the 2-D printer will turn on and off, and if it is turned on it will know what to turn on and off again.\\n2. If the 3-D printer is on a stand, then you can place the controller directly on the center of the plane or the bottom of the plane in place of the controller. This way, you can be able to turn the controller into a 2-D controller that is on either side of the plane, if the other is on either side. This way, you can hold the controller in the middle of the plane and move the controller from place to place. This is also an easy way to'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "generator(\"In this course, we will teach you how to\", max_length=500, num_return_sequences=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea7d997-5651-4999-8d07-647565f632c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67757550-62c6-4362-a65a-37f208c3bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949764490127563, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(question=\"Where do I work?\",\n",
    "                  context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5a173-661a-4d82-afe6-82b7f19099be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\"\"\"Due to the worldwide rapid adoption of mobile-based applications in libraries to foster the delivery of information services on mobile devices of library users, there are vast and growing collections of peer-reviewed research and conference papers available in various online databases. Analyzing the literature related to mobile-based library services is one method to conduct future research to enhance library collections and services in the digital age. The primary goal of this paper is to review the most relevant literature in the field to better understand these previous research works, identify trends and to determine the research gaps for future studies. A comprehensive and systematic review of the literature on mobile-based applications in libraries and information centres of peer-reviewed research papers, and conference proceedings published in online databases (ProQuest-LISA and Web of Science) during the last seven years (2015–2022) was conducted for critical analysis and to address the present trends of mobile-based applications in these studies. We identified that many studies have described the use of mobile apps–based applications like Mobile Online Public Access Catalogue (MOPAC), Mobile websites, Mobile databases, WhatsApp, SMS, RSS, and Quick Response (QR) Codes in the enhancement of library collections and services around the globe. We observed that 75.93% of documents were published as research articles, and 42.59% of publications were identified under the two authorship patterns. Also, the authors investigated the current and future state of the research in this field by synthesizing the results of published high- quality experimental studies and systematic mapping studies on related disciplines. We hope that this study will be helpful for librarians and information professionals to better understand and implement the applications of mobile technologies for enhancement of library collections and services in the virtual world.\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
